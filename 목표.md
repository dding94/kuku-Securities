# 🎯# Kuku Securities (쿠쿠 증권) 프로젝트 목표

> **"Why"가 이끄는 기술적 의사결정, 그리고 극한의 안정성**
> 실제 증권사 수준의 고민을 담은 MSA 기반 트레이딩 플랫폼을 구축합니다.

---

## 1. 프로젝트 핵심 가치 (Core Values)

이 프로젝트는 단순한 기능 구현을 넘어, **"왜 이 기술을 썼는가?"**와 **"장애 상황에서 어떻게 버티는가?"**를 증명하는 데 초점을 맞춥니다.

1.  **Why-Driven Engineering**: 모든 기술 선택(Java, MSA, Kafka, Redis 등)은 대안과의 비교, 트레이드오프 분석, 그리고 실험 데이터에 기반합니다.
2.  **Resilience (회복 탄력성)**: 분산 환경(MSA)에서 필연적인 네트워크 실패, 지연, 그리고 **"알 수 없음(Unknown)"** 상태를 우아하게 처리합니다.
3.  **Data Integrity (데이터 무결성)**: 금융 시스템의 본질인 원장(Ledger) 데이터는 어떤 상황에서도 유실되거나 오염되지 않아야 합니다.
4.  **High Concurrency (고동시성)**: 대규모 트래픽과 주문 폭주 상황에서도 동시성 이슈(Race Condition)를 완벽하게 제어합니다.

---

## 2. 시스템 아키텍처 (MSA)

각 도메인은 독립적인 배포와 확장이 가능한 마이크로서비스로 구성됩니다.

*   **Core Ledger (원장 서비스)**: 계좌, 예수금, 주식 잔고를 관리하는 **Source of Truth**. 이중 부기(Double-entry bookkeeping) 원칙 준수.
*   **Order System (주문 서비스)**: 매수/매도 주문 접수, 체결 처리, 주문 상태 관리. 고동시성 제어의 핵심.
*   **Market Data (시세 서비스)**: 실시간 주가 정보 수신 및 브로드캐스팅 (WebSocket/Netty).
*   **API Gateway**: 인증/인가, Rate Limiting, 라우팅.

---

## 3. 상세 로드맵 (16주 완성)

### Phase 1: The Foundation & The Ledger (원장 시스템) - "돈은 거짓말하지 않는다"

*   **Week 1: 프로젝트 셋업 및 MSA 기반 마련**
    *   [x] Multi-module Gradle 구성 (Domain, API, Common).
    *   [x] Docker Compose & Kubernetes 로컬 환경 구성.
    *   [x] CI/CD 파이프라인 구축 (Github Actions).
    *   [x] **[ADR]** Monolithic vs MSA: 초기 단계에서 MSA를 선택한 이유와 비용 분석.

*   **Week 2: 원장(Ledger) 도메인 설계 및 DB 모델링**
    *   [ ] 이중 부기 데이터 모델 설계 (Journal, Account, Balance).
    *   [ ] MySQL 테이블 설계 및 인덱스 전략.
    *   [ ] **[ADR]** MySQL vs PostgreSQL: 금융 데이터 처리에 적합한 RDBMS 선택.

*   **Week 3: 원장 정합성 구현 (Transaction & Isolation)**
    *   [ ] 입출금, 자산 이동 트랜잭션 구현.
    *   [ ] 트랜잭션 격리 수준(Isolation Level)에 따른 동시성 테스트.
    *   [ ] **[Deep Dive]** Spring `@Transactional`의 동작 원리와 주의점.

*   **Week 4: 원장 시스템 검증 테스트**
    *   [ ] 동시성 테스트 (동일 계좌 동시 입출금 시 정합성 검증).
    *   [ ] 100만 건 이상의 대량 데이터 처리 성능 테스트.

### Phase 2: The Order System & Concurrency (주문 시스템) - "폭주하는 트래픽을 견뎌라"

*   **Week 5: 주문 상태 머신(State Machine) 설계**
    *   [ ] 주문 생명주기 관리 (접수 -> 거래소 전송 -> 체결/거부 -> 정산).
    *   [ ] 상태 패턴(State Pattern) 적용 및 코드 유연성 확보.

*   **Week 6: 동시성 제어 전략 (Concurrency Control)**
    *   [ ] 재고(예수금/주식) 차감 시 Race Condition 해결.
    *   [ ] **[Experiment]** Optimistic Lock(JPA @Version) vs Pessimistic Lock(DB X-Lock) vs Redis Distributed Lock 성능 및 부하 비교.
    *   [ ] **[ADR]** 상황별 최적의 락킹 전략 선정.

*   **Week 7: 멱등성(Idempotency) 및 중복 주문 방지**
    *   [ ] 네트워크 타임아웃으로 인한 재시도 시 중복 결제/주문 방지.
    *   [ ] Idempotency Key 패턴 구현.

*   **Week 8: 주문 시스템 부하 테스트**
    *   [ ] nGrinder/k6를 이용한 고부하 주문 테스트.
    *   [ ] Throughput(TPS) 및 Latency 측정 및 병목 구간 튜닝.
    *   [ ] **[Troubleshooting]** OS(CPU, Memory, I/O) 및 Network 레벨의 병목 구간 분석 및 해결 경험.

### Phase 3: Distributed Resilience (분산 시스템의 안정성) - "실패는 일상이다"

*   **Week 9: 서비스 간 통신 및 장애 전파 차단**
    *   [ ] Feign Client vs gRPC 도입 검토.
    *   [ ] Resilience4j를 이용한 Circuit Breaker, Retry, Rate Limiter 적용.
    *   [ ] **[ADR]** 동기(HTTP) vs 비동기(Messaging) 통신 방식의 선택 기준.

*   **Week 10: "Unknown" 상태 처리 (핵심 차별화 포인트)**
    *   [ ] 외부 시스템(PG, 거래소) 응답 지연/타임아웃 시 "알 수 없음" 상태 처리 로직.
    *   [ ] 자동 조회 및 상태 동기화 배치(Batch) 구현.
    *   [ ] 망분리 환경/레거시 연동을 가정한 설계 고려.

*   **Week 11: 분산 트랜잭션과 데이터 일관성**
    *   [ ] SAGA 패턴 (Choreography vs Orchestration) 적용 검토.
    *   [ ] Kafka를 이용한 Eventual Consistency 구현 (주문 체결 -> 잔고 반영).
    *   [ ] **[ADR]** 2PC(Two-Phase Commit)를 지양하고 Eventual Consistency를 택한 이유.

*   **Week 12: 관측성(Observability) 및 카오스 엔지니어링**
    *   [ ] Distributed Tracing (Zipkin/Jaeger) 도입.
    *   [ ] ELK Stack (Logstash, Elasticsearch, Kibana) 로그 모니터링.
    *   [ ] **[Full-Stack Monitoring]** Spring(Req/Res), Tomcat(Thread Pool), JVM(Heap, GC), OS(File Descriptors, Context Switches) 전 계층 모니터링 구축.
    *   [ ] **[Chaos]** 임의의 서비스/DB를 강제 종료시켰을 때 시스템의 거동 확인 및 복구 훈련.

### Phase 4: Real-time & Optimization (실시간성 및 최적화) - "0.1초의 승부"

*   **Week 13: 실시간 시세 처리 (Real-time Data)**
    *   [ ] Netty / Spring WebFlux를 이용한 WebSocket 서버 구축.
    *   [ ] **[Network Programming]** Netty EventLoop, ByteBuf 동작 원리 심층 분석 및 TCP/IP 튜닝 (Nagle, Keep-alive).
    *   [ ] 수천 명의 클라이언트에게 실시간 호가 브로드캐스팅.

*   **Week 14: 대용량 데이터 파이프라인 (Kafka)**
    *   [ ] Kafka를 이용한 시세 데이터 Ingestion 및 처리.
    *   [ ] **[ADR]** RabbitMQ vs Kafka: 대용량 스트림 처리에 Kafka를 선택한 이유.

*   **Week 15: 캐싱 전략 및 성능 최적화**
    *   [ ] Redis Caching (Look-aside, Write-back) 전략.
    *   [ ] Hot Key 문제 해결 및 Cache Stampede 방지.
    *   [ ] JVM GC Tuning (GC Logs 분석, Heap Dump 분석) 및 HikariCP 설정 최적화.
    *   [ ] **[Infra Tuning]** 고동시성 처리를 위한 커널 파라미터 튜닝 (`ulimit`, `somaxconn`, `tcp_tw_reuse` 등).

*   **Week 16: 최종 점검 및 문서화**
    *   [ ] 전체 아키텍처 문서화 및 트러블슈팅 로그 정리.
    *   [ ] 모의 투자 기능 최종 시연.

---

## 4. 채용 공고 매핑 (Checklist)

*   [ ] **Java, Spring Framework**: 프로젝트 전체 기반 기술.
*   [ ] **합리적이고 효율적인 방식 선택 (Why)**: 모든 주차별 ADR 작성.
*   [ ] **배포/운영/안정성/성능 고민**: CI/CD, Circuit Breaker, 부하 테스트, 튜닝.
*   [ ] **Redis, Kafka, Kubernetes, ELK**: 해당 기술 스택 적극 활용.
*   [ ] **대용량 트래픽/동시성 처리**: 주문 시스템 및 시세 처리에서 중점적으로 다룸.
*   [ ] **실시간 데이터 처리**: WebSocket 및 Kafka 파이프라인.
*   [ ] **끈기 있는 문제 해결**: "Unknown" 상태 처리 및 카오스 테스트.